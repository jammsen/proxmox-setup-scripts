# Before use please create persistent volume for Ollama models or bind mount a host directory
# Run this before running docker compose up: docker volume create ollama-models
# Monitoring snippet:
# watch -d "docker exec ollama-main-gpu ollama list && echo \"\\nollama-main-gpu\\n\" && docker exec ollama-main-gpu ollama ps && echo \"\\nollama-rocm6-gpu\\n\" && docker exec ollama-rocm6-gpu ollama ps && echo \"\\nollama-rocm7-gpu\\n\" && docker exec ollama-rocm7-gpu ollama ps && echo \"\\nollama-vulkan-gpu\\n\" && docker exec ollama-vulkan-gpu ollama ps"
services:
    ollama-main-gpu:
        image: ollama/ollama:rocm
        container_name: ollama-main-gpu
        ports:
            - 11434:11434
        devices:
            - /dev/kfd
            - /dev/dri
        environment:
            - HSA_OVERRIDE_GFX_VERSION=11.5.1
            - HSA_ENABLE_SDMA=0
        group_add:
            - video
        cap_add:
            - SYS_PTRACE
        security_opt:
            - seccomp=unconfined
        ipc: host
        volumes:
            - ollama-models:/root/.ollama
    ollama-rocm6-gpu:
        image: ghcr.io/phueper/ollama-linux-amd-apu:optm-rocm_6_7
        container_name: ollama-rocm6-gpu
        ports:
            - 11435:11434
        devices:
            - /dev/kfd
            - /dev/dri
        environment:
            - OLLAMA_LLM_LIBRARY=rocm_v6
            - OLLAMA_FLASH_ATTENTION=true
            - OLLAMA_DEBUG=1
            - HSA_OVERRIDE_GFX_VERSION=11.5.1
            - HSA_ENABLE_SDMA=0
        group_add:
            - video
        cap_add:
            - SYS_PTRACE
        security_opt:
            - seccomp=unconfined
        ipc: host
        volumes:
            - ollama-models:/root/.ollama
    ollama-rocm7-gpu:
        image: ghcr.io/phueper/ollama-linux-amd-apu:optm-rocm_6_7
        container_name: ollama-rocm7-gpu
        ports:
            - 11436:11434
        devices:
            - /dev/kfd
            - /dev/dri
        environment:
            - OLLAMA_LLM_LIBRARY=rocm_v7
            - OLLAMA_FLASH_ATTENTION=true
            - OLLAMA_DEBUG=1
            - HSA_OVERRIDE_GFX_VERSION=11.5.1
            - HSA_ENABLE_SDMA=0
        group_add:
            - video
        cap_add:
            - SYS_PTRACE
        security_opt:
            - seccomp=unconfined
        ipc: host
        volumes:
            - ollama-models:/root/.ollama
    ollama-vulkan-gpu:
        image: ghcr.io/phueper/ollama-linux-amd-apu:optm-rocm_6_7
        container_name: ollama-vulkan-gpu
        ports:
            - 11437:11434
        devices:
            - /dev/kfd
            - /dev/dri
        environment:
            - OLLAMA_LLM_LIBRARY=vulkan
            - OLLAMA_FLASH_ATTENTION=true
            - OLLAMA_DEBUG=1
            - HSA_OVERRIDE_GFX_VERSION=11.5.1
            - HSA_ENABLE_SDMA=0
        group_add:
            - video
        cap_add:
            - SYS_PTRACE
        security_opt:
            - seccomp=unconfined
        ipc: host
        volumes:
            - ollama-models:/root/.ollama

volumes:
    ollama-models:
        external: true
        name: ollama-models